services:
  app:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        VITE_USE_CSHARP_API: "true"
        VITE_API_BASE_URL: "http://localhost:5174"
    ports:
      - "5174:80"
    volumes:
      - .:/app
    environment:
      - NODE_ENV=development
      - VITE_USE_CSHARP_API=true
      - VITE_API_BASE_URL=http://localhost:5174
    depends_on:
      - api
    restart: unless-stopped
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost" ]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '0.50'
          memory: 512M

  # app-dev:
  #   image: node:20-alpine
  #   working_dir: /app
  #   volumes:
  #     - .:/app
  #   command: sh -c "npm install && npm run dev"
  #   ports:
  #     - "5173:8080"
  #   environment:
  #     - NODE_ENV=development
  #     - VITE_SITE_URL=http://localhost:5173
  #   restart: unless-stopped

  api:
    build:
      context: ./api
      dockerfile: Dockerfile
    ports:
      - "5227:8080"
    environment:
      - ASPNETCORE_ENVIRONMENT=Development
      - ASPNETCORE_URLS=http://+:8080
      - SUPABASE_URL=https://nwfwbjmzbwuyxehindpv.supabase.co
      - SUPABASE_JWKS_URL=https://nwfwbjmzbwuyxehindpv.supabase.co/auth/v1/.well-known/jwks.json
      - SUPABASE_POSTGREST_URL=https://nwfwbjmzbwuyxehindpv.supabase.co/rest/v1
      - SUPABASE_FUNCTIONS_URL=https://nwfwbjmzbwuyxehindpv.supabase.co/functions/v1
      - SUPABASE_ANON_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Im53Zndiam16Ynd1eXhlaGluZHB2Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3NDg1MjkyMzksImV4cCI6MjA2NDEwNTIzOX0.s_vI6z46NAYlpB8K0wznCWEr_cFcnsHh7Qn4LmsUZU0
      - ALLOW_ORIGINS=http://localhost:5174,http://localhost:5173,http://localhost:3000,http://localhost:8081
    restart: unless-stopped
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8080/healthz" ]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '0.50'
          memory: 512M

  wiremock:
    image: wiremock/wiremock:latest
    ports:
      - "8080:8080"
    volumes:
      - ./api/tests/Retroscope.Api.IntegrationTests/wiremock-mappings:/home/wiremock
    environment:
      - WIREMOCK_PORT=8080
    restart: unless-stopped
    profiles:
      - integration-test

  # tts-server:
  #   image: ghcr.io/coqui-ai/tts
  #   ports:
  #     - "5002:5002"
  #   volumes:
  #     - tts_models:/root/.local/share/tts
  #   gpus:
  #     - driver: nvidia
  #       count: all
  #   # Override entrypoint to call python3 directly
  #   entrypoint:
  #     - python3
  #     - TTS/server/server.py
  #   # Now give all of your server flags as a YAML list
  #   command:
  #     - --model_name
  #     - tts_models/en/ljspeech/tacotron2-DDC_ph
  #     - --use_cuda
  #     - "true"
  #   restart: unless-stopped
volumes:
  tts_models:


